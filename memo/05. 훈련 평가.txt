훈련데이터와 평가데이터는 분리되어야한다.
평가데이터가 훈련데이터와 동일하면 또는 훈련데이터비율이 너무 높으면 (답지를 알고있는 상태에서 시험 보는 것과 비슷) 과적합 문제가 생길 수 있다.
학습데이터를 분리할때 골고루 분포된 표본을 추출하는게 더 좋다. 앞에서부터 순서대로 70%를 추출하는 것보다 전체중에서 골고루 70%를 추출하는게 더 좋다.

- 벡터는 transpose를 해도 변화가 없다.
- predict할때 벡터를 파라미터로 받아도 행렬(2차원)으로 반환한다.
- scikit-learn에는 왠만한 전처리함수, 머신러닝 모델이 다 탑재되있다.
-
x_train, x_test, y_train, y_test = train_test_split(
    x, y, test_size=0.3, shuffle=True, random_state=42
)  
# test_size=0.3 대신 train_size=0.7 로 해도된다.
# 디폴트 값 : train_size=0.75 // test_size=0.25 // shffle=True // random_state=None
# shuffle: 섞을지 말지 결정. False 옵션이면 학습데이터를 앞에서 순서대로 뽑음.
# random_state: 섞을 때 "섞는 순서"를 고정해서 결과를 반복 가능하게 만듦. None이면 훈련때마다 학습(테스트)데이터 바뀜. shuffle이 False면 쓸모없는 옵션
# 데이터가 많아질수록 shuffle을 해야한다. 실제 손실계산과 훈련은 부동소수점(실수)단위로 진행되는데, 만약 훈련범위 밖 데이터가 비선형적으로 분포될경우 뒷부분은 오차가 커질 수있다. 
# random_state를 None으로 하면 그에따른 난수값을 알 수없다. 훈련결과 잘 나왔을때 해당 난수값을 찾을 수없으므로 random_state는 지정해놓고 바꿔가면서 훈련하는게 좋다.
# 시계열데이터는 첫번째로 shuffle을 하지 않고 추출한 다음 그 다음에 shuffle을 해야한다. 시간이 들어간 데이터라서 그런 것 같다.

인공지능 종류 : 회귀 or 분류
회귀 : 실수값을 계산하여 오차를 찾아내고 줄여나가는 방식(일차방정식)
회귀와 분류는 같은 평가지표를 쓸 수 없다.

회귀에서 쓰이는 두가지 평가지표 : 
- RMSE : MSE(평균오차)에 루트를 씌운 것을 의미. 제곱값을 그냥쓰면 너무 커서 그냥 단순히 줄이기 위한 용도이다.
또한 과적합 될 수록 rmse가 낮아지는 경향이 있다.
- R2 : 회귀분석에서의 결정계수 (분류에서의 정확도에 대응). 모델의 설명력을 나타냄.