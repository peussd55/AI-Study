[BCELoss 특징]
-> 0 또는 1로만 계산 
-> 수식에 넣으면 예측값과 손실값이 반대면 손실이 무한대 가깝게 수렴 
-> 오차가 가중되어서 MSE보다 효과적으로 학습가능
==================================================================================================================
[CrossEntropyLoss 작동순서]
1. 정답라벨(y)을 위치정보로 인덱싱한다(원핫인코딩아님). 인덱싱 갯수는 모델의 output_dim에 의해 정해진다.
2. output_dim 만큼의 크기를 가지는 예측값 벡터가 생성되고 여기에 예측확률을 채워넣는다.(ex : output_dim이 3이면 [-1.2, 0.3, 1.8] 도출)
2.1. softmax가 예측확률의 총합이 1이 되게한다. (ex : [-1.2, 0.3, 1.8] -> [0.02, 0.3, 0.68])
3. 정답라벨의 인덱스에 있는 값(정답이 1이라면 0.3)만 꺼내서 수식에 넣고 loss를 도출한다. (ex : -log(0.3)만 계산)
==================================================================================================================
[(참고) 텐서플로우 categorical_crossentropy 함수]
1. 사용자가 직접 output_dim 크기만큼 정답라벨(y)을 원핫인코딩으로 벡터화해야한다. (ex : [1 0 0] [0 1 0] [0 0 1])
2. output_dim 만큼의 크기를 가지는 예측값 벡터가 생성되고 여기에 예측확률을 채워넣는다.(ex : output_dim이 3이면 [-1.2, 0.3, 1.8] 도출)
2.1. softmax가 예측확률의 총합이 1이 되게한다. (ex : [-1.2, 0.3, 1.8] -> [0.02, 0.3, 0.68])
3. 두 인코딩된 벡터를 전부 연산하여 loss를 도출한다. (ex : -[(0*log(0.2)) + (1*log(0.3)) + (0*log(0.5))])
