import numpy as np
import pandas as pd

from tensorflow.keras.preprocessing.image import ImageDataGenerator
import time as time
import datetime

from tensorflow.keras.models import Sequential ,Model
from tensorflow.keras.layers import Dense, Flatten, Dropout ,Conv2D ,Input, MaxPooling2D ,BatchNormalization
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint
from sklearn.metrics import accuracy_score
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical

# ë°ì´í„° ì •ê·œí™”
x_train = x_train/255.
y_train = y_train/255.

#ì¸ìŠ¤í„´ìŠ¤í™”
datagen = ImageDataGenerator(
    #rescale=1./255,        # 0~255 ìŠ¤ì¼€ì¼ë§, ì •ê·œí™”
    horizontal_flip=True,  # ìˆ˜í‰ ë’¤ì§‘ê¸°  <- ë°ì´í„° ì¦í­ ë˜ëŠ” ë³€í™˜ /ì¢Œìš°ë°˜ì „
    # vertical_flip=True,    # ìˆ˜ì§ ë’¤ì§‘ê¸° <- ë°ì´í„° ì¦í­ ë˜ëŠ” ë³€í™˜ /ìƒí•˜ë°˜ì „
    width_shift_range=0.1, # í‰í–‰ì´ë™ 10%
    # height_shift_range=0.1,
    rotation_range=15,      
    # zoom_range=1.2,
    # shear_range=0.7,        #ì¢Œí‘œí•˜ë‚˜ë¥¼ ê³ ì •ì‹œí‚¤ê³ , ë‹¤ë¥¸ ëª‡ê°œì˜ ì¢Œí‘œë¥¼ ì´ë™ì‹œí‚¤ëŠ” ë³€í™˜(ì°Œë¶€ ë§Œë“¤ê¸°)
    # fill_mode='nearest'
) 

#ë°ì´í„° ì¦í­
augment_size=40000  # ê¸°ì¡´ ë°ì´í„° 6ë§Œê°œì—ì„œ 10ë§Œê°œë¡œ ì¦ê°€

randidx=np.random.randint(x_train.shape[0], size=augment_size)

print(randidx) #[26709 24797 39699 ... 27794 58644 56222]
print(np.min(randidx), np.max(randidx)) #2 59999

x_augmented=x_train[randidx].copy() #4ë§Œê°œì˜ ë°ì´í„°copyë¡œ ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ í• ë‹¹

print(x_augmented.shape) #(40000, 28, 28)
y_augmented = y_train[randidx].copy()

#í˜•íƒœ ë³€ê²½ (40000, 28, 28) -> (40000, 28, 28,1)
x_augmented = x_augmented.reshape(x_augmented.shape[0],x_augmented.shape[1],x_augmented.shape[2],1)
# y_augmented = y_augmented.reshape(y_augmented.shape[0],y_augmented.shape[1],y_augmented.shape[2],1)

x_augmented = datagen.flow(
    x_augmented,
    y_augmented,
    batch_size=augment_size,
    shuffle=False,
).next()[0]


xy_train= train_datagen.flow_from_directory(path_train,               #ê²½ë¡œ
                                  target_size=(200,200),    #ì‚¬ì´ì¦ˆ ê·œê²©ì¼ì¹˜, í° ì‚¬ì´ì¦ˆëŠ” ì¶•ì†Œ, ì‘ì€ì‚¬ì´ì¦ˆëŠ” í™•ëŒ€
                                  batch_size=100,            #
                                  class_mode='binary',
                                  color_mode='rgb',
                                  shuffle=True,
                                  seed=1,
                                  )

#ê¸°ì¡´ë°ì´í„° ì°¨ì› ë³€ê²½
x_train=x_train.reshape(60000,28,28,1)
x_test=x_test.reshape(-1,28,28,1)

#ê¸°ì¡´ ë°ì´í„°+ì¦ê°• ë°ì´í„° í•©ì¹˜ê¸°
x_train=np.concatenate((x_train, x_augmented))
y_train=np.concatenate((y_train, y_augmented))


; -------------------------------------------------------
np_path='./_data/_save_npy/keras46/gender/'
# np.save(np_path+"keras_44_01_x_trian.npy", arr=x)
# np.save(np_path+"keras_44_01_y_trian.npy", arr=y)

s_time=time.time()
x_train = np.load(np_path+"keras_46_07_x_train_128.npy")
y_train = np.load(np_path+"keras_46_07_y_train_128.npy")

e_time=time.time()

print(x_train.shape, y_train.shape)
print("ì‹œê°„:", round(e_time-s_time,2))

x_train, x_test, y_train, y_test = train_test_split(
    x_train, y_train,
    test_size=0.2,
    random_state=121 
)

# print(x_train.shape)# (2647, 250, 250, 3)
# print(x_test.shape)# (662, 250, 250, 3)
# print(y_train.shape)#  (2647,)
# print(y_test.shape)# (662,)
# exit()

path = './_save/keras28_mcp/02_california/'
model = load_model(path + '0604_1145_0336-0.4321.hdf5')

#OnehotEnder
from tensorflow.keras.utils import to_categorical
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

model = Sequential()
model.add(Conv2D(64, (3,3), padding='same', activation='relu', input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3])))
model.add(BatchNormalization())
model.add(MaxPooling2D())
model.add(Dropout(0.25))

model.add(Conv2D(128, (3,3), padding='same', activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D())
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])

from sklearn.utils.class_weight import compute_class_weight
class_weights = compute_class_weight(class_weight='balanced',
                                     classes=np.unique(y_train),
                                     y=y_train)
class_weights_dict = dict(enumerate(class_weights))

import datetime
date = datetime.datetime.now().strftime("%m%d_%H%M")
filepath = f'./_save/keras39_cifar10{date}' + '.hdf5'

mcp = ModelCheckpoint(
    monitor='val_loss',
    mode='min',
    save_best_only=True, # ê°€ì¥ ì¢‹ì€ ê°’ì„ ì°¾ì•„ì„œ ì €ì¥í•˜ê¸° ìœ„í•œ
    filepath=filepath
)

es =  EarlyStopping(
    monitor='val_loss',
    mode = 'min',
    patience=20,
    restore_best_weights=True
)

import os
import glob
import re

def keep_best_model_and_delete_others(folder_path):
    # í´ë” ë‚´ .hdf5 íŒŒì¼ ë¦¬ìŠ¤íŠ¸
    files = glob.glob(os.path.join(folder_path, '*.hdf5'))

    if not files:
        print("ì‚­ì œí•  ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # íŒŒì¼ëª…ì—ì„œ val_loss ê°’ì„ ì •ê·œí‘œí˜„ì‹ìœ¼ë¡œ ì¶”ì¶œ
    def extract_val_loss(filename):
        basename = os.path.basename(filename)
        match = re.search(r'-(\d+\.\d+)\.hdf5$', basename)
        if match:
            return float(match.group(1))
        else:
            return float('inf')  # val_loss ì—†ìœ¼ë©´ ë¬´í•œëŒ€ë¡œ ì²˜ë¦¬

    # val_loss ê¸°ì¤€ ìµœì†Œê°’ ì°¾ê¸°
    best_file = min(files, key=extract_val_loss)
    print(f"âœ… ë‚¨ê¸¸ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ íŒŒì¼: {best_file}")

    # ê°€ì¥ ì¢‹ì€ íŒŒì¼ ì œì™¸ ëª¨ë‘ ì‚­ì œ
    for f in files:
        if f != best_file:
            try:
                os.remove(f)
                print(f"ì‚­ì œ ì™„ë£Œ: {f}")
            except Exception as e:
                print(f"ì‚­ì œ ì‹¤íŒ¨: {f} - {e}")


epochs=100
batch_size=64

model.fit(x_train, y_train, 
          epochs=epochs,
          batch_size=batch_size,
          validation_split=0.2,
          verbose = 1,
          callbacks=[es,mcp],
          class_weight=class_weights_dict
          )

results = model.evaluate(x_train, y_train)
y_pred = model.predict(x_test)
y_pred_labels = (y_pred > 0.5).astype(int).reshape(-1)

print("\nğŸ“‰ Loss :", results[0])
print("âœ… Accuracy :",results[1])

# -------------------- ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ì •ë¦¬ --------------------
checkpoint_folder = './_save/keras46/'  # ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ê²½ë¡œ
keep_best_model_and_delete_others(checkpoint_folder)


if y_test.ndim == 2 and y_test.shape[1] > 1:
    y_true_labels = np.argmax(y_test, axis=1)
else:
    y_true_labels = y_test.astype(int)
    
import matplotlib.pyplot as plt

plt.rcParams['font.family'] = 'Malgun Gothic'  # ìœˆë„ìš°: ë§‘ì€ ê³ ë”•
num_images = 15

plt.figure(figsize=(15, 8))
for i in range(num_images):
    plt.subplot(3, 5, i + 1)
    plt.imshow(x_test[i])
    plt.axis('off')
    
    true_label = y_true_labels[i]
    pred_label = y_pred_labels[i]
    color = 'green' if true_label == pred_label else 'red'
    plt.title(f"ì—°ìŠµ: {pred_label}\n ì •ë‹µ: {true_label}", color=color)

plt.suptitle("ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” (ë…¹ìƒ‰: ì •ë‹µ, ë¹¨ê°•: ì˜¤ë‹µ)", fontsize=16)
plt.tight_layout()
plt.show()


