"단계 (Level)","목표 (Objective)","주요 기술 및 개념 (Key Skills & Concepts)","대상 (Target Level)"
"1단계
(기본 역량)","모델 훈련의 전 과정을 스스로 통제하고, 결과의 재현성을 보장하며, 문제 발생 시 원인을 분석하고 디버깅하는 능력.","- 커스텀 평가지표 (Custom Metrics) 구현
:Accuracy만으로는 불충분한 경우(e.g., 불균형 데이터셋)에 문제에 맞는 지표(e.g., F1-score, Precision, Recall, AUC)를 직접 구현하여 모델을 다각도로 평가.

- Early Stopping (ES) 직접 구현
: 검증 손실(Validation Loss)이 더 이상 개선되지 않을 때, 과적합을 방지하고 불필요한 컴퓨팅 자원 낭비를 막기 위해 훈련을 조기 종료하는 로직 구현.

- Model Checkpointing (MCP) 직접 구현
: 훈련 중 검증 성능이 가장 좋았던 시점의 모델 가중치(state_dict)를 파일로 저장하여 최적의 결과물을 확보하고, 예기치 않은 중단 시 훈련을 재개.

- 학습 과정 시각화 (Training Visualization)
:matplotlib등을 사용해 Epoch에 따른 Loss 및 Metric 곡선을 시각화하여, 학습의 안정성, 수렴 여부, 과적합/과소적합 징후를 직관적으로 파악.","주니어 필수 역량
(Must-have)"
"2단계
(차별화 역량)","모델의 성능을 한계까지 끌어올리고, 모든 실험 과정을 체계적으로 기록/관리하여 효율적인 연구개발 및 협업을 수행하는 능력.","- 실험 관리 및 로깅 (Experiment Management & Logging)
:TensorBoard,W&B등을 활용하여 하이퍼파라미터, 평가지표, 시스템 리소스 사용량 등 모든 실험 내용을 영구적으로 기록, 추적, 비교 및 공유.

- 설정 관리 (Configuration Management)
:YAML파일이나argparse를 사용해 코드와 설정을 분리함으로써, 코드 변경 없이 다양한 조건의 실험을 반복하고 실험의 재현성을 보장하는 엔지니어링 습관.

- 성능 향상 기술 (Performance Enhancement)
-  학습률 스케줄러: 학습 단계에 따라 학습률을 동적으로 조절하여 빠르고 안정적인 수렴을 유도 (e.g.,CosineAnnealingLR,ReduceLROnPlateau).
-  고급 데이터 증강: 모델의 일반화 성능을 극적으로 향상시키는 기법 적용 (e.g.,CutMix,Mixup,RandAugment).
-  혼합 정밀도 학습: FP16/FP32 연산을 혼합하여 GPU 메모리 사용량을 줄이고 학습 속도를 가속화 (torch.cuda.amp).","주니어 차별화 역량
(Nice-to-have)"
"3단계
(심화/전문가)","단일 머신의 한계를 넘어선 대규모 모델을 개발하고, 전사적인 ML 시스템을 안정적으로 자동화하여 지속적인 가치를 창출하는 능력.","A. 대규모 학습/추론 최적화 (Large-Scale Optimization)
-  분산 학습: 단일 GPU에 담을 수 없는 초거대 모델(LLM 등)을 여러 GPU/노드에 분산시켜 학습 (e.g.,DistributedDataParallel,DeepSpeed).
-  모델 경량화: 학습된 모델의 가중치를 압축(양자화)하거나 불필요한 연결을 제거(가지치기)하여 추론 속도를 높이고 엣지 디바이스에 배포.
-  지식 증류: 크고 복잡한 '선생님 모델'의 지식을 작고 빠른 '학생 모델'에 전수하여, 성능 손실을 최소화하며 모델을 경량화.

B. MLOps (Machine Learning Operations)
-  ML 파이프라인 자동화: 데이터 전처리-학습-평가-배포 과정을 코드로 자동화하여 CI/CD 구현 (e.g.,Kubeflow,MLflow,Airflow).
-  피처 스토어: 학습과 추론 시점의 피처 불일치(Training-Serving Skew) 문제를 방지하고, 전사적으로 피처를 재사용/관리하는 중앙 저장소.
-  모델 모니터링 및 재학습: 배포된 모델의 성능 저하(Model Drift)를 실시간으로 탐지하고, 조건 충족 시 자동으로 재학습 파이프라인을 트리거하여 최신 성능 유지.","시니어 / ML 전문가
(Senior / Specialist)"