(1) 이미지인식에 합성곱을 사용하는 이유?
일반 MLP(Multi Layer Perceptron)를 사용하면 특징을 추출하여 가중을 하지 않고 모든 정보를 학습(픽셀 하나하나를 특징으로해서 학습)
	-> 과적합 
지역적 특징을 반영하지 못한다. (학습데이터와 테스트데이터가 1차원으로 펴지고나면 공간적 구조가 사라져 서로 특징 매칭을 못시킴 = 생김새 정보 소실)
	-> 과적합
	-> cnn : 같은 모양이면 위치가 어디라도 같다는 걸 알 수있지만, dnn은 픽셀위치마다 별도 가중치를 써야해서 같다는걸 인지못함

(2) cnn의 3단계 구조 : 합성곱 층 - 풀링 층 - 밀집층
 1. 합성곱 층 - 패턴인식. 지역적특징추출. 주로 relu함수를 써서 비선형성을 학습. 이미지*커널 -> 피처 맵. 추출하고싶은 특징수 만큼 features를 입력한다.
	(추가 : 채널 = [입력데이터(이미지) 또는 출력데이터(피쳐맵)]의 깊이(=이미지의 갯수(R,G,B)만큼 곱))
	(추가 : 커널 = 가중치행렬. 이미지가 이 커널과 유사한 패턴을 가지고있으면 그 지역은 곱연산이 증폭되고 없으면 약화되어 지역간 곱연산 차이가 커진다)
 2. 풀링 층 - 피처맵의 크기를 줄이는 단계. 연산량을 줄이기위해 사용한다. 피처안의 피처를 추출하는 단계이기도하다. 과적합을 줄이는 효과도 있다(성능 향상)
	(추가 : 피처맵이 클 경우의 특징 = 디테일한 패턴추출 가능. 연산량이 큼.)
 3. 밀집층 - 최종 출력을 생성하는 단계. Flatten을 써서 차원축소하여 들어온다. 합성곱층은 지역 확률만 계산했지만 최종 전체 확률계산을 위한 연산을 하는 밀집층이 필요하다.

(3) 인간 시각정보 처리과정과 합성곱층의 유사성 : 선 -> 도형 -> 물체 -> 얼굴 등. 상위 영역으로 갈수록 인식하는 feature복잡도가 올라간다.

1.1. 커널vs필터
커널 : 이미지를 돌아다니는 특정모양의 거름망
필터 : 특징을 찾기 위해 이미지의 갯수만큼의 커널을 가지고있는 녀석. 커널들의 집합

1.2. 제로패딩
외곽에 0을 추가하여 피처맵의 크기가 줄어드는 것을 방지(ex: 4x4 피처맵을 (2,2)커널을 지나서도 4x4을 유지하고싶을때 사용 )
- 하는 이유1 : 피처맵이 작으면 커널이 돌아다닐수없음
- 하는 이유2 : 외곽에 중요한 특징이 있는 이미지를 학습할 경우, 예컨데 27x27를 maxpooling하면 외곽 컬럼 한개가 소실되고 13x13 피처맵으로 변환되는데 이 소실되는 외곽컬럼을 살려야할 경우


이미지가 RGB 3개일때는 필터도 3개의 커널을 준비한다. RGB 3개의 커널로 출력하면 합쳐서 하나의 피처 맵을 만든다.
커널 갯수 = 채널 갯수
feature당 할당받는 커널의 갯수 = 입력 데이터의 채널수
