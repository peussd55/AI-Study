######################################################################################################################
[훈련구조]
def train(model, criterion, optimizer, x, y):
    # model.train()                     # 디폴트. [훈련모드] : 드랍아웃, 배치노말 적용
    optimizer.zero_grad()               # 기울기 초기화
                                        # 각 배치마다 기울기를 초기화(0으로)하여, 기울기 누적에 의한 문제 해결
    hypothesis = model(x)               # y = xw + b.   # hypothsis : predict와 유사
    loss = criterion(hypothesis, y)     # loss = mse() = 시그마(y-hypothesis)^2/n

    loss.backward()                     # 기울기(gradient)값까지만 계산 : ∂L/∂w
    optimizer.step()                    # 가중치 갱신 : w = w - lr * ∂L/∂w
    
    return loss.item()
    # 위의 한 스텝이 1epoch

######################################################################################################################
[평가구조]
def evaluate(model, criterion, x, y):
    model.eval()        # 필수적용. [평가모드] : 드랍아웃, 배치노말을 쓰지 않겠다.(평가에선 절대 드랍아웃, 배치노말 사용X)
    
    with torch.no_grad():     # 기울기갱신X. 평가에서 모델을 수행할때 기울기계산을 하지않기 위해 no_grad로 감싼다.
        y_predict = model(x)
        loss2 = criterion(y, y_predict) # loss의 최종값
    return loss2.item()

def evaluate(model, criterion, x, y):
    model.eval()        # 필수적용. [평가모드] : 드랍아웃, 배치노말을 쓰지 않겠다.(평가에선 절대 드랍아웃, 배치노말 사용X)
    
    # with torch.no_grad():     # 기울기계산X (메모리폭증, 불필요한 연산제거)
    #     y_predict = model(x)
    #     loss2 = criterion(y, y_predict) # loss의 최종값
    
    # 위 구문을 풀어쓰면 다음과같다.
    torch.set_grad_enabled(False)
    y_predict = model(x)
    loss2 = criterion(y, y_predict) # loss의 최종값
    torch.set_grad_enabled(True)
    
    """
    y_predict = model(x)
    loss2 = criterion(y, y_predict) # loss의 최종값
    만 써도 되지만 파이토치의 디폴트 옵션인 자동미분계산을 끄기위해서 사용한다.
    -> 안끄면 evaluate때 가중치 갱신이 한번 더 되어서 뒤의 계산에 영향을 미친다.
    """
    
    return loss2.item()

######################################################################################################################
[아웃풋 변환]
# detach() : 텐서를 계산 그래프에서 분리 / 출력이 1차원일 경우 item() 사용가능
# cpu() : numpy가 읽을 수 있또록 cpu메모리로 옮김
# numpy() : 텐서를 넘파이 배열로 변환

######################################################################################################################
[텐서변환관련 (torch.tensor가 판다스데이터를 텐서변환할때 오류가 안나게하려면)]
1. 인덱스가 문자형이면 괜찮다 : 문자형일경우 인덱스를 무시하고 값(넘파이배열)만 가지고 연산하기때문에 변환이 된다.
2. 인덱스가 수치형일 경우 : 0을 포함하면서 연속적이어야한다. 둘 중 한 조건이라도 만족을 못하면 ValueError: could not determine the shape of object type 오류가 발생한다. 
 -> train/test분리할 때 shuffle=True 조건으로 분리하면 연속적으로 분리되지 않게 될 확률이 높기때문에 거의 오류가 난다.
=> 결론 : tensor변환할땐 그냥 속편하게 전부 nparray로 바꾸고 하자.