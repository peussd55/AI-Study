스케일링(Scaling)을 하는 이유는 다음과 같습니다.

---

## 1. **특성(피처)마다 값의 범위가 다르기 때문**

- 데이터의 각 컬럼(특성)마다 값의 단위와 범위가 다를 수 있습니다.  
  예를 들어, `나이`는 0~100, `재산`은 0~1,000,000처럼 차이가 크면,  
  머신러닝/딥러닝 모델이 값이 큰 특성에 더 큰 가중치를 부여하게 되어  
  **특정 특성에 편향된 학습**이 일어날 수 있습니다[2][3][4][6][7].

---

## 2. **학습 효율 및 성능 향상**

- 값의 범위가 크거나 작은 특성이 섞여 있으면,  
  모델이 최적의 가중치를 찾기 어렵고,  
  **학습 속도가 느려지거나, 성능이 저하될 수 있습니다**[2][3][4][6].
- 특히 딥러닝에서는 입력값이 너무 크거나 작으면  
  **가중치가 0으로 수렴하거나 발산**하는 문제가 생길 수 있습니다[3][5][7].

---

## 3. **동일한 조건에서 특성 비교 가능**

- 스케일링을 하면 모든 특성이 **동일한 범위**(예: 0~1, 평균 0/표준편차 1 등)로 맞춰져  
  서로 다른 특성 간의 **상대적 중요성**을 제대로 비교할 수 있습니다[2][3][4][6].

---

## 4. **거리 기반 알고리즘에 필수**

- KNN, SVM, K-Means 등 **거리 기반 알고리즘**에서는  
  스케일링이 되어 있지 않으면 값이 큰 특성만 모델에 영향을 주게 됩니다[5][7].

---

## 5. **이상치 및 분포 조정**

- 스케일링을 통해 이상치 탐지나 분포 조정(표준화, 정규화 등)이 용이해집니다[2][4][7].

---

## 6. **일관된 평가 및 해석**

- 스케일링하면 모델의 해석과 시각화가 더 명확해집니다[5].

---

### **정리**

> **스케일링은 각 특성의 값 범위를 일정하게 맞춰서,  
> 모델이 모든 특성을 균등하게 학습할 수 있도록 하며,  
> 학습 효율과 예측 성능을 높이고, 특정 특성에 편향된 학습을 방지하는 데 필수적인 전처리 과정입니다.**[2][3][4][5][6][7]
