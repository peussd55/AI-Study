1. 학습을돌릴때 loss가 주기적으로 튀는 경우가있다 이럴 경우의 파라미터는 좋지 않은 케이스니 소거한다.

2. 너무 많은 노드를 가진 히든레이어를 추가해도 좋지 않다. epochs, batch_size, 히든레이어를 적절하게 조합해야한다.

3. 모델 훈련(fit)때 loss는 낮게 나오는데 평가(evluate)때 loss가 높게 나오는 경우 :
        -> 훈련 : model.fit(x_train, y_train, epochs=600, batch_size=32)
        -> 평가 : loss = model.evaluate(x_test, y_test)
  :: 과적합된경우임.

4.1 히든레이어 튜닝할때 병목(중간이 좁아지는 구조), 역피라미드구조는 성능이 그다지 좋지 않다.
4.2. 많이 쓰이는 구조 : 피라미드(넓은 시작 좁은 끝), 균일 두 가지가 많이쓰인다.

5.
[주요 하이퍼파라미터 튜닝 방법]
(1) 그리드 서치 (Grid Search)
그리드 서치는 미리 정의된 하이퍼파라미터 값들의 모든 조합을 철저하게 탐색하는 방법입니다. 예를 들어, SVM 모델에서 C 값으로 [1000]과 gamma 값으로 [0.1, 0.2, 0.5, 1.0]을 설정하면, 이 두 집합의 카르테시안 곱(모든 조합)을 평가합니다. 이 방법은:
- 장점: 포괄적이고 구현이 간단함
- 단점: 계산 비용이 많이 들고 하이퍼파라미터 수가 증가할수록 조합이 기하급수적으로 늘어남

(2) 랜덤 서치 (Random Search)
랜덤 서치는 하이퍼파라미터 공간에서 무작위로 값을 선택하여 평가합니다. 이 방법은:

- 장점: 그리드 서치보다 효율적이며, 특히 일부 하이퍼파라미터만 성능에 큰 영향을 미칠 때 더 효과적
- 단점: 여전히 많은 시도가 필요할 수 있음

(3) 베이지안 최적화 (Bayesian Optimization)
베이지안 최적화는 이전 평가 결과를 바탕으로 확률 모델을 구축하여 다음에 평가할 하이퍼파라미터를 지능적으로 선택합니다. 이 방법은:

- 장점: 더 적은 평가로 더 나은 결과를 얻을 수 있으며, 탐색과 활용 사이의 균형을 맞춤
- 단점: 구현이 복잡하고 대규모 병렬 처리에 제한이 있음

(4) 조기 중단 기반 방법 (Early Stopping-based)
Hyperband나 Successive Halving과 같은 알고리즘은 성능이 낮은 모델을 일찍 중단시켜 계산 자원을 절약합니다. 이 방법은:

- 장점: 대규모 하이퍼파라미터 공간에서 효율적이며, 특히 평가 비용이 높을 때 유용
- 단점: 초기 설정에 따라 결과가 달라질 수 있음